{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import preprocessing as pp\n",
    "import implementations as imp\n",
    "import helpers as hlp\n",
    "import os\n",
    "from functions import *\n",
    "import csv\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/maelynenguyen/Desktop/dataset_to_release/'\n",
    "x_train_, x_test_, y_train_, train_ids_, test_ids_ = hlp.load_csv_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown values replaced with NaN, according to the documentation\n",
      "Max median NaN score rows :  0.6060963867246555\n",
      "Max median NaN score columns :  0.7652518774030354\n",
      "Number of rows dropped because of a NaN score > 0.5:  37081\n",
      "Number of columns dropped because of a NaN score > 0.5:  150\n",
      "Number of columns with std < 0.1: 5\n",
      "Number of columns with correl_coef > 0.95: 11\n",
      "Handling NaN values...\n",
      "Data clipped between 5th and 95th percentiles\n",
      "Number of columns with std < 0.1 after cleaning: 11\n",
      "Number of columns with corr_coef> 0.95 after cleaning: 14\n",
      "The data has been cleaned and standardized\n",
      "The cleaned x_train data has the following shape:  (291054, 130)\n",
      "The cleaned y_train has the following shape:  (291054,)\n",
      "The cleaned x_test has the following shape:  (109379, 130)\n",
      "(291054,)\n"
     ]
    }
   ],
   "source": [
    "x, x_submit, y = pp.clean_data_final(x_train_, y_train_, x_test_)\n",
    "\n",
    "X_train = np.concatenate((x, np.zeros((x.shape[0], 1)) + 1), axis=1)\n",
    "X_test = np.concatenate((x_submit, np.zeros((x_submit.shape[0], 1)) + 1), axis=1)\n",
    "\n",
    "\n",
    "assert x.shape[1] + 1 == X_train.shape[1]\n",
    "\n",
    "Y_train = y.copy()\n",
    "Y_train = np.where(y == -1, 0, 1)\n",
    "Y_train = Y_train.astype(int) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train_split, x_test, y_test_split = pp.split_data(X_train, y, 0.8) # 80% training, 20% testing\n",
    "\n",
    "\n",
    "y_train = y_train_split.copy()\n",
    "y_train = np.where(y_train_split == -1, 0, 1).astype(int) \n",
    "\n",
    "y_test = y_test_split.copy()\n",
    "y_test = np.where(y_test_split == -1,0,1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_iters\": [1500],\n",
    "    \"gamma\": [1, 0.1, 0.001],\n",
    "    \"lambda_\": [1e-4, 1e-5, 1e-6],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Iters: 1500, Gamma: 1, Avg Loss: 0.22988858420150513\n",
      "Max Iters: 1500, Gamma: 0.1, Avg Loss: 0.22999879896363645\n",
      "Max Iters: 1500, Gamma: 0.001, Avg Loss: 0.4901988597087352\n"
     ]
    }
   ],
   "source": [
    "w_grid, best_params_logistic, losses = grid_search_logistic_regression(y_train, x_train, param_grid, np.zeros(x_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found:  {'max_iters': 1500, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters found: \", best_params_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_log, loss, losses = imp.logistic_regression(y_train, x_train, np.zeros(x_train.shape[1]), 1500, 1, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining the Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold for the Logistic Regression:  0.2\n"
     ]
    }
   ],
   "source": [
    "y_train_log = imp.sigmoid(x_train @ w_log)\n",
    "thr_ = best_threshold(y_train_log, y_train_split) \n",
    "print(\"Optimal Threshold for the Logistic Regression: \", thr_)\n",
    "#y_train_log = np.where(y_train_log > thr_, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_log = imp.sigmoid(x_test @ w_log)\n",
    "y_test_log = np.where(y_test_log > thr_, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.41184387617765816\n",
      "Accuracy 0.8648709006888733\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score\",f1_score_(y_test_split, y_test_log))\n",
    "print(\"Accuracy\",accuracy_score_(y_test_split, y_test_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the submission\n",
    "y_pred = imp.sigmoid(X_test @ w_log)\n",
    "y_test_pred = np.where(y_pred > thr_, 1, -1)  \n",
    "hlp.create_csv_submission(test_ids_, y_test_pred, \"logistic_regression.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing of an Adam optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_adam(y, x, param_grid, initial_w):\n",
    "    best_params = {}\n",
    "    best_loss = np.inf\n",
    "    losses = []\n",
    "    for max_iters in param_grid[\"max_iters\"]:\n",
    "        for gamma in param_grid[\"gamma\"]:\n",
    "                w = adam_optimizer(y, x, initial_w, max_iters, gamma)\n",
    "                loss = compute_loss(y, x, w)  # Assuming you have a function to compute the loss\n",
    "                losses.append(loss)\n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    best_params[\"max_iters\"] = max_iters\n",
    "                    best_params[\"gamma\"] = gamma\n",
    "                    best_params[\"loss\"] = loss\n",
    "    return w, best_params, losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_adam_grid, best_params_adam, losses = grid_search_adam(y_train, x_train, param_grid, np.zeros(x_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found:  {'max_iters': 1500, 'gamma': 0.1, 'lambda_': 0.0001, 'loss': 6.698937126717145}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters found: \", best_params_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_adam = adam_optimizer(y_train, x_train, np.zeros(x_train.shape[1]), 1500, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold for Adam 0.2\n"
     ]
    }
   ],
   "source": [
    "y_train_adam = imp.sigmoid(np.dot(x_train, w_adam))\n",
    "optimal_threshold = best_threshold(y_train_adam, y_train_split)  \n",
    "print(\"Optimal Threshold for Adam\", optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_adam = imp.sigmoid(np.dot(x_test, w_adam))\n",
    "y_test_adam = np.where(y_test_adam > optimal_threshold, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.41168599464763606\n",
      "Accuracy 0.8640463142704987\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score\",f1_score_(y_test_split, y_test_adam))\n",
    "print(\"Accuracy\",accuracy_score_(y_test_split, y_test_adam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlp.create_csv_submission(test_ids_, y_test_adam, \"adam.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Iters: 1500, Gamma: 1, Lambda: 0.0001, Avg Loss: 0.2297606158482602\n",
      "Max Iters: 1500, Gamma: 1, Lambda: 1e-05, Avg Loss: 0.22976041756546514\n",
      "Max Iters: 1500, Gamma: 1, Lambda: 1e-06, Avg Loss: 0.2297616920874618\n",
      "Max Iters: 1500, Gamma: 0.1, Lambda: 0.0001, Avg Loss: 0.22993585946287043\n",
      "Max Iters: 1500, Gamma: 0.1, Lambda: 1e-05, Avg Loss: 0.2298919415847535\n",
      "Max Iters: 1500, Gamma: 0.1, Lambda: 1e-06, Avg Loss: 0.22988811346281293\n",
      "Max Iters: 1500, Gamma: 0.001, Lambda: 0.0001, Avg Loss: 0.4900305808722318\n",
      "Max Iters: 1500, Gamma: 0.001, Lambda: 1e-05, Avg Loss: 0.4900109562359458\n",
      "Max Iters: 1500, Gamma: 0.001, Lambda: 1e-06, Avg Loss: 0.49000899364689304\n"
     ]
    }
   ],
   "source": [
    "w_reg, best_params, losses = grid_search_reg_logistic_regression(y_train, x_train, param_grid, np.zeros(x_train.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found:  {'max_iters': 1500, 'gamma': 1, 'lambda_': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters found: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_reg, loss_reg = imp.reg_logistic_regression(y_train, x_train, 1e-05, np.zeros(x_train.shape[1]), 1500, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold found for the regularized model:  0.21\n"
     ]
    }
   ],
   "source": [
    "y_train_reg = imp.sigmoid(np.dot(x_train, w_reg))\n",
    "optimal_threshold_reg = best_threshold(y_train_reg, y_train_split)  # y_train is (-1,1) and y_train_reg is (0,1)\n",
    "print(\"Optimal threshold found for the regularized model: \", optimal_threshold_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reg = imp.sigmoid(np.dot(x_test, w_reg))\n",
    "y_pred_reg = np.where(y_pred_reg > optimal_threshold_reg, 1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.407858973363361\n",
      "Accuracy 0.869011011664462\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score\",f1_score_(y_test_split, y_pred_reg))\n",
    "print(\"Accuracy\",accuracy_score_(y_test_split, y_pred_reg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLCourse1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
